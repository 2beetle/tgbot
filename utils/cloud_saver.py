import asyncio
from collections import defaultdict
from datetime import datetime, timedelta
from html import escape

import aiohttp

from config.config import CLOUD_SAVER_HOST, CLOUD_SAVER_USERNAME, CLOUD_SAVER_PASSWORD, CLOUD_TYPE_MAP


class CloudSaver:
    # ä¼šè¯æœ€å¤§å­˜æ´»æ—¶é—´ï¼š1å°æ—¶
    _SESSION_MAX_AGE = timedelta(hours=1)

    def __init__(self):
        self.username = CLOUD_SAVER_USERNAME
        self.password = CLOUD_SAVER_PASSWORD
        self.host = CLOUD_SAVER_HOST
        self._session = None
        self._session_created_at = None
        self._token = None
        self.cloud_type_map = CLOUD_TYPE_MAP

    async def _get_session(self):
        """è·å–æˆ–åˆ›å»ºä¼šè¯ï¼Œæ”¯æŒä¼šè¯è¿‡æœŸè‡ªåŠ¨é‡å»º"""
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦éœ€è¦é‡æ–°åˆ›å»º
        need_new_session = (
            self._session is None or
            self._session_created_at is None or
            self._session.closed or
            datetime.now() - self._session_created_at > self._SESSION_MAX_AGE
        )

        if need_new_session:
            # å…³é—­æ—§ä¼šè¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if self._session and not self._session.closed:
                try:
                    await self._session.close()
                except Exception:
                    pass

            # åˆ›å»ºæ–°ä¼šè¯ï¼Œæ·»åŠ è¶…æ—¶å’Œè¿æ¥å™¨é…ç½®
            timeout = aiohttp.ClientTimeout(
                total=30,        # æ€»è¶…æ—¶ 30 ç§’
                connect=10,      # è¿æ¥è¶…æ—¶ 10 ç§’
                sock_read=20     # è¯»å–è¶…æ—¶ 20 ç§’
            )

            connector = aiohttp.TCPConnector(
                limit=100,           # æœ€å¤§è¿æ¥æ•°
                limit_per_host=30,   # æ¯ä¸ªä¸»æœºçš„æœ€å¤§è¿æ¥æ•°
                ttl_dns_cache=300,   # DNS ç¼“å­˜ 5 åˆ†é’Ÿ
                force_close=False,   # ä½¿ç”¨ HTTP keep-alive
                enable_cleanup_closed=True  # æ¸…ç†å…³é—­çš„è¿æ¥
            )

            self._session = aiohttp.ClientSession(
                timeout=timeout,
                connector=connector
            )
            self._session_created_at = datetime.now()

        return self._session

    async def _get_token(self):
        """è·å–è®¤è¯ä»¤ç‰Œï¼Œå¦‚æœä»¤ç‰Œè¿‡æœŸåˆ™é‡æ–°è·å–"""
        if self._token is None:
            session = await self._get_session()
            async with session.post(
                f'{self.host}/api/user/login',
                json={'username': self.username, 'password': self.password}
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    self._token = data.get('data', {}).get('token')
        return self._token

    async def close(self):
        """å…³é—­ä¼šè¯å¹¶æ¸…ç†èµ„æº"""
        if self._session and not self._session.closed:
            try:
                await self._session.close()
                await asyncio.sleep(0.1)
            except Exception:
                pass
            finally:
                self._session = None
                self._session_created_at = None
                self._token = None

    async def get(self, url, params=None):
        token = await self._get_token()
        session = await self._get_session()
        async with session.get(
            url=f'{self.host}/{url}',
            params=params,
            headers={'Authorization': f'Bearer {token}'}
        ) as resp:
            data = await resp.json()
            return data

    async def search(self, search_content):
        return await self.get('/api/search', {'keyword': search_content})

    async def format_links_by_channel(self, data):
        result = []

        for channel_data in data:
            channel_name = channel_data.get("channelInfo", {}).get("name", "æœªçŸ¥é¢‘é“")
            # æŒ‰ç½‘ç›˜ç±»å‹åˆ†ç»„ï¼Œæ¯ç»„å­˜ (title, link) åˆ—è¡¨
            cloudtype_links = defaultdict(list)

            for item in channel_data.get("list", []):
                title = item.get("title", "æ— æ ‡é¢˜")
                for link in item.get("cloudLinks", []):
                    url = link.get("link")
                    raw_type = link.get("cloudType", "").upper()
                    if url:
                        cloudtype_links[raw_type].append((title, url))

            if not cloudtype_links:
                continue

            lines = [f"ğŸ“¡ <b>{escape(channel_name)}</b>"]

            for raw_type, items in cloudtype_links.items():
                cloud_type_name = self.cloud_type_map.get(raw_type, raw_type)
                lines.append(f"\nğŸ”¸ <b>{cloud_type_name}</b>")
                for title, url in items:
                    lines.append(f'ğŸ”— <a href="{escape(url)}">{escape(title)}</a>')

            result.append('\n'.join(lines))
        return result

    async def format_links_by_cloud_type(self, data, links_valid: dict, preferred_clouds=None):
        result = []
        # æŒ‰ç½‘ç›˜ç±»å‹åˆ†ç»„ï¼Œæ¯ç»„å­˜ (title, link) åˆ—è¡¨
        cloudtype_links = defaultdict(list)

        for channel_data in data:
            for item in channel_data.get("list", []):
                title = item.get("title", "æ— æ ‡é¢˜")
                for link in item.get("cloudLinks", []):
                    url = link.get("link")
                    raw_type = link.get("cloudType", "").upper()
                    if url:
                        cloudtype_links[raw_type].append((title, url))

        for cloud_type, resources in cloudtype_links.items():
            cloud_type_name = self.cloud_type_map.get(cloud_type)
            # å¦‚æœç”¨æˆ·é…ç½®äº†å¸¸ç”¨äº‘ç›˜ï¼Œè·³è¿‡ä¸åœ¨é…ç½®ä¸­çš„ç½‘ç›˜ç±»å‹
            if preferred_clouds is not None and cloud_type_name not in preferred_clouds:
                continue

            # è¿‡æ»¤æ‰æ— æ•ˆçŠ¶æ€çš„é“¾æ¥ï¼Œåªä¿ç•™"æœ‰æ•ˆ"æˆ–"çŠ¶æ€æœªçŸ¥"çš„é“¾æ¥
            valid_resources = [
                resource for resource in resources
                if links_valid.get(resource[1], 'çŠ¶æ€æœªçŸ¥') in ('æœ‰æ•ˆ', 'çŠ¶æ€æœªçŸ¥')
            ]

            for i in range(0, len(valid_resources), 25):
                lines = [f"â˜ï¸ <b>{self.cloud_type_map.get(cloud_type)}</b>ï¼ˆcsèµ„æºï¼‰"]
                chunk_data = valid_resources[i:i + 25]
                for resource in chunk_data:
                    lines.append(f'ğŸ”— <a href="{resource[1]}">{resource[0].replace('<', '[').replace('>', ']')}</a> ï¼ˆ{links_valid.get(resource[1], 'çŠ¶æ€æœªçŸ¥')}ï¼‰')

                result.append('\n'.join(lines))
        return result